---
title: "Using Docker and Knitr to Create Reproducible and Extensible Publications"
author: "David Mawdsley, Robert Haines and Caroline Jay<p>The University of Manchester</p>"
date: "C4RR Workshop, Cambridge <p>28 June 2017</p>"
output: 
  revealjs::revealjs_presentation:
    transition: fade
    theme: solarized
    reveal_options:
      controls: false
---

## The problem

[](start with the question, “what’s the one thing I want people to learn, or feel, or do, as a result of hearing this?”. Tim Harford)

[](To understand why writing a reproducible paper is a good thing, and how it could alter the scholarly publication landscape.)

- The scholarly publication process is slow and lumpy
- But scientific knowledge is incremental
	* And there are always more questions than there's time to answer
- How can Docker and reproducible research help?

## Outline

- Background to reproducible research
- Where Docker fits into this
- Benefits, challenges and open questions 

## Reproducible Research


![](https://upload.wikimedia.org/wikipedia/en/6/62/Literate_Programming_book_cover.jpg?download)

<h6>Image:  <a href="//en.wikipedia.org/wiki/File:Literate_Programming_book_cover.jpg">Wikipedia</a></h6>

---


![](algoToPapers0.png)

---

![](algoToPapers1.png)

---

![](algoToPapers2.png)

---


![](algoToPapers3.png)

---

## Reproducible Research in R

- `knitr` allows us to interleave markdown or `LaTeX` with `R` code
	* R session persists throughout document
		- Code chunks can be cached
	* Supports other languages -- but no persistence between chunks
 
  * Can produce something that looks _identical_ to a "normal" paper
    	- Paper source needed for reproducibility
    	

---

```{r, echo=FALSE}
writeLines(readLines("ExamplePaper.Rnw"))
```

---

![](ExamplePaper.png)

## Reproducible != Reusable

- Reproducibility is a good thing
	* It makes you do things *properly*
	* It lets others check your work
- It doesn't (necessarily) make it easy to _reuse_ or _extend_ your work 
 ** repeatability too **

## Docker Pipelines for Reproducible, Reusable Research

- By breaking our analysis pipeline into sections we obtain a
_more flexible_ workflow, which makes incremental improvement / extension of the work easier
- Docker facilitates this
- Use a Makefile to handle dependencies between "modules" 
	* Makes the manuscript just another "modules"

## Example

---

![](WorkflowPipeline.png)

---

![](WorkflowContainers.png)

## Docker images
- Each module contains its own Makefile
- Example:
  * CppMT tracking
  
  
---

![](ObjectTracking.png)

  
## "Master" Makefile
- Handles dependencies between the Docker image modules
- Calls the final Docker image to produce manuscript

## Extensible papers

- _TODO: Note similarity to ArXiv build process (though that's LaTeX only)_
- _Publisher provides "manuscript" Docker image, author responsible for other Docker images?_
- Docker provides the containerisation which makes it easy to build the manuscript anywhere
- Submit manuscript by inviting publisher to clone manuscript repository
- Publisher `Make`s package and sends to reviewers
- Reviewers review paper (and underlying code)
- Article published; paper of record
- Repository (sent to e.g. Figshare) is repository of record

## Extensible papers

- Publisher has produced paper of record
- Extensions (or corrections) to the paper can be built by:
`git pull`
`make`
- VC and Makefile make it obvious what's changed ==> lighter weight peer review


## The paper as software

- Treating the paper as "just another part" of the software development process lets us use:
	* Version control
	* Continuous integration
	* Unit testing
  

## Tips

- Test textual assertions with `R` code:

> "The value of $\tau^2$ was at least twice its value under the previous model"

```
if(tausq.new < 2.0 * tausq.old) {
  warning("Text assertion failed")
}
```

- Make intermediate files in modules "precious" 
	* Avoids wasted work in slow modules
- Make the Knitr paper runable on native system
  	* Makes debugging easier
## Challenges

- More difficult than working non-reproducibility
   * A difficult sell?
   * Pre-prepared infrastructure?
- Slow analyses
- Tying Docker and R together
- Compiling the manuscript text outwith the process
- Analysis vs results (i.e. analysis is the processing of, e.g. CppMT output)
- User decisions in compilation process - i.e. setting bounding box 
- Random numbers
- Modules running in Docker containers are more difficult to debug/extract intermediate information from

## Benefits

- Can work each element of the paper back to its source
- It makes fixing mistakes easier
- Each module (Docker image) can be used independently of the others
  - Reusability _and_ reproducibility
- Input directories to each module are mounted read only
	- Guarantees data can't be overwitten

## An industrial Fabergé Egg?

![](FabergeEggQuoteCropped.png)

<h6><a href=https://doi.org/10.1145/5948.315654 >Bentley, J., Knuth, D., & McIlroy, D. (1986). Programming pearls. Communications of the ACM, 29(6), 471–483. </a></h6>


## The future shape of academic research outputs

- Should something like an academic paper be the "standard" research output?
  * Is this better than, e.g. a Jupyter notebook? If so, why?
    - Audience; who reads it and why?
    - Researcher evaluation/assessment; cultural shift, relative (perceived) values of, e.g. notbooks vs journal articles
- Rightly or wrongly academic papers are likely to be a primary means of scientific dissemination for a while

## Bibliography/other reading

* Gandrud, C. (2013). Reproducible Research with R and R Studio.
* [Lowndes, J. S. S., et al  (2017). Our path to better science in less time using open data science tools. Nature Ecology & Evolution, 1(6), 160.](https://doi.org/10.1038/s41559-017-0160)
* [TechBlog: C. Titus Brown: Predicting the paper of the future, Nature Jobs (2017)](http://blogs.nature.com/naturejobs/2017/06/01/techblog-c-titus-brown-predicting-the-paper-of-the-future/)

